{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesi√≥n de Spark\n",
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"DataTransfer\").config(\"spark.jars\", \"/opt/bitnami/spark/jars/sqljdbc4.jar\").getOrCreate()\n",
    "\n",
    "# Leer los datos de SQL Server en paralelo usando Spark\n",
    "df = spark.read.format(\"jdbc\").options(\n",
    "    url=\"jdbc:sqlserver://192.168.100.8:1433;databaseName=test-spark\",\n",
    "    driver=\"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "    dbtable=\"test_1\",\n",
    "    user=\"sa\",\n",
    "    password=\"h4ckm3.2024\"\n",
    ").load()\n",
    "\n",
    "# Escribir los datos en la base de datos de destino en paralelo\n",
    "#df.write.format(\"jdbc\").options(\n",
    "#    url=\"jdbc:sqlserver://destination_server:1433;databaseName=destination_db\",\n",
    "#    driver=\"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "#    dbtable=\"destination_table\",\n",
    "#    user=\"your_username\",\n",
    "#    password=\"your_password\"\n",
    "#).mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
